{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import errors\n",
    "from Lexer.Lexer_generator import Lexer\n",
    "from Parser.Parser import ParserError, LR1Parser\n",
    "from Parser.HulkParser import HulkParser\n",
    "from Grammar.Grammar import G\n",
    "from Grammar import Grammar as Gr\n",
    "from Lexer.Tokens_lexer import tokens\n",
    "from Semantic.semantic_analysis_pipeline import semantic_analysis_pipeline\n",
    "from Code_gen.code_generator import CCodeGenerator\n",
    "from cmp.evaluation import evaluate_reverse_parse\n",
    "import os\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=LR1Parser(G) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexer= Lexer(tokens,G.EOF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSemanticError: Circular dependency inheritance. Near line: 3, column: 17\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['./archivo'], returncode=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def print_error(message):\n",
    "    red = \"\\033[31m\"\n",
    "    refresh = \"\\033[0m\"\n",
    "    print(f\"{red}{message}{refresh}\")\n",
    "\n",
    "text= '''\n",
    "type A inherits B {\n",
    "}\n",
    "type B inherits A {\n",
    "\n",
    "}\n",
    "5;\n",
    "            '''\n",
    "\n",
    "try:\n",
    "    tokens_=lexer.tokenize(text)\n",
    "except errors.LexerError as e:\n",
    "    print_error(e)\n",
    "\n",
    "try: \n",
    "    parse, operations = parser([t.token_type for t in tokens_])\n",
    "except ParserError as e:\n",
    "    error_token = tokens_[e.token_index]\n",
    "    error_text = errors.HulkSyntacticError.PARSING_ERROR % error_token.lex\n",
    "    error_ = [errors.HulkSyntacticError(error_text, error_token.row, error_token.column,)]\n",
    "    print_error(error_)\n",
    "    \n",
    "ast=evaluate_reverse_parse(parse,operations,tokens_)\n",
    "semantic_ast, semantic_errors,context,_=semantic_analysis_pipeline(ast)\n",
    "if semantic_errors:\n",
    "    for e in semantic_errors:\n",
    "        print_error(e)\n",
    "    \n",
    "codegen=CCodeGenerator()\n",
    "code= codegen(semantic_ast,context)\n",
    "try:\n",
    "    with open(Path(f'{\"archivo\"}.c'), 'w') as f:\n",
    "        f.write(code)\n",
    "except FileNotFoundError:\n",
    "    error = errors.HulkIOError(errors.HulkIOError.ERROR_WRITING_FILE % output_path)\n",
    "    print_error(error)\n",
    "    \n",
    "subprocess.run([\"gcc\",\"-o\",'archivo','archivo.c', \"-lm\"])\n",
    "subprocess.run(['./archivo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class A:\n",
    "    x=\"5\"\n",
    "\n",
    "class B(A):\n",
    "    y=\"4\"\n",
    "\n",
    "p=B()\n",
    "p.x=\"9\"\n",
    "p.x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
